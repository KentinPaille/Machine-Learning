{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a0e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f121add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dup news : 0        False\n",
      "1        False\n",
      "2         True\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "44893    False\n",
      "44894    False\n",
      "44895    False\n",
      "44896     True\n",
      "44897     True\n",
      "Length: 44898, dtype: bool\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   is_fake  44898 non-null  int64 \n",
      " 1   title    44898 non-null  object\n",
      " 2   text     44898 non-null  object\n",
      " 3   subject  44898 non-null  object\n",
      " 4   date     44898 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_format_data(file_path, is_fake):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.insert(0, \"is_fake\", is_fake)\n",
    "    return df\n",
    "\n",
    "df_fake = load_format_data(\"./data/Fake.csv\", 1)\n",
    "df_true = load_format_data(\"./data/True.csv\", 0)\n",
    "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "duplicates = df.duplicated(subset=[\"text\"], keep=False)\n",
    "\n",
    "print(\" dup news :\", duplicates)\n",
    "\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e1abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake sample words: ['Proficiency', 'ugly.Brandon', 'Sheindie', 'THEY?!With', '2017Nancy', '(D-SC)', 'Violence.Here', 'others.These', 'letters:', 'wage-rule', 'printouts', '2016Finally,', 'Amendment.The', 'dole!Palo', '.https://twitter.com/P0TUSTrump/status/773724216247984129Trump', 'pic.twitter.com/cvQP6Fegz4', '#fallfashion', 'DailyMailOnline', '$117,425,683Chile', 'more.There']\n",
      "Real sample words : ['Zawy', 'Senegal.', 'egregiousness', 'DOUBLELINE', 'expensive,”', '“clawback”', '“Voters', 'precedent.”', 'TransWest', 'Ceresney,', '“accusations', '62.48', 'hold?”', 'watch.”', 'Palanker.', 'redistricting.', 'Representatives.”', 'Gotthard', 'campaigners’', 'APG']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fake_words = Counter(\" \".join(df[df[\"is_fake\"]==1][\"text\"]).split())\n",
    "real_words = Counter(\" \".join(df[df[\"is_fake\"]==0][\"text\"]).split())\n",
    "\n",
    "exclusive_fake = set(fake_words) - set(real_words)\n",
    "exclusive_real = set(real_words) - set(fake_words)\n",
    "\n",
    "print(\"Fake sample words:\", list(exclusive_fake)[:20])\n",
    "print(\"Real sample words :\", list(exclusive_real)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As the dataset is full of duplicates news, we remove them to be able to train our model more accuratly\n",
    "\n",
    "df = df.drop(index=np.where(duplicates)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a741e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.69663986e-02\n",
      "  -7.56175746e-03 -6.82923348e-03]\n",
      " [ 1.00000000e+00  0.00000000e+00  0.00000000e+00 ... -4.06542373e-02\n",
      "  -3.72816940e-02 -1.30096507e-02]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00 ...  3.31941197e-02\n",
      "   1.69316288e-02  4.26213405e-02]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -3.57372910e-03\n",
      "  -2.89139248e-03 -3.12366127e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  9.02913919e-04\n",
      "   3.97174220e-02  1.68906563e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.51597287e-02\n",
      "  -2.81053654e-02  6.09964133e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text_col = [\"title\", \"text\"]\n",
    "df['full_text'] = df[text_col].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_text = vectorizer.fit_transform(df['full_text'][1:])\n",
    "\n",
    "# Réduction de dimensionnalité avec SVD\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_text_reduced = svd.fit_transform(X_text)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_num_scaled = encoder.fit_transform(np.array(df[\"subject\"][1:]).reshape(-1, 1))\n",
    "X_num_scaled_dense = X_num_scaled.toarray()\n",
    "\n",
    "X = np.hstack([X_num_scaled_dense, X_text_reduced])\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdfa436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_text.shape)\n",
    "# print(X_num_scaled.shape)\n",
    "# X = np.hstack([X_num_scaled.toarray(), X_text.toarray()])\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e21e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33505,)\n",
      "(26804, 57)\n",
      "(6701, 57)\n",
      "(26804,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label = df.pop(\"is_fake\")\n",
    "label = label[1:]\n",
    "\n",
    "\n",
    "print(label.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c45b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483ec6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"RandomForest Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ae4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Train Accuracy: 0.98649\n",
      "LogisticRegression Test Accuracy: 0.98776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=0.01)\n",
    "lr.fit(X_train, y_train)\n",
    "train_accuracy = lr.score(X_train, y_train)\n",
    "print(f\"LogisticRegression Train Accuracy: {train_accuracy:.5f}\")\n",
    "test_accuracy = lr.score(X_test, y_test)\n",
    "print(f\"LogisticRegression Test Accuracy: {test_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2104095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6206536337860021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dc = DummyClassifier()\n",
    "dc.fit(X_train, y_train)\n",
    "test_dc_accuracy = dc.score(X_test, y_test)\n",
    "print(test_dc_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
